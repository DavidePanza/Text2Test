{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8286ea1d",
   "metadata": {},
   "source": [
    "### Test splitting on chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d74256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "sys.path.append(\"../../src\")  \n",
    "import toc_parser\n",
    "import raw_text_processing\n",
    "import text_processing\n",
    "import chromadb_utils\n",
    "import chunks_processing\n",
    "import messages_templates\n",
    "\n",
    "importlib.reload(toc_parser)\n",
    "importlib.reload(raw_text_processing)\n",
    "importlib.reload(text_processing)\n",
    "importlib.reload(chromadb_utils)\n",
    "importlib.reload(chunks_processing)\n",
    "importlib.reload(messages_templates)\n",
    "\n",
    "from raw_text_processing import process_pdf, extract_pages_range, extract_chapters\n",
    "from toc_parser import extract_chapters_from_toc\n",
    "from text_processing import text_chunking, chapters_chunking\n",
    "from chromadb_utils import initialize_chromadb, initialize_collection, update_collection\n",
    "from chunks_processing import query_collection, get_chapter_context\n",
    "from messages_templates import chapter_prompt, chapter_prompt_edgecase, book_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "d92ac5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary mapping example keys to PDF paths\n",
    "examples = {\n",
    "    \"pdf_path1\": \"../../data/mcelreath_2020_statistical-rethinking.pdf\",\n",
    "    \"pdf_path2\": \"../../data/Theory of Statistic.pdf\",\n",
    "    \"pdf_path3\": \"../../data/Deep Learning with Python.pdf\",\n",
    "    \"pdf_path4\": \"../../data/Natural_Image_Statistics.pdf\",\n",
    "    \"pdf_path5\": \"../../data/mml-book.pdf\"\n",
    "}\n",
    "\n",
    "# Dictionary mapping example keys to page ranges to extract content from\n",
    "content_page_ranges = {\n",
    "    \"pdf_path1\": range(5, 8),\n",
    "    \"pdf_path2\": range(10, 17),\n",
    "    \"pdf_path3\": range(7, 13),\n",
    "    \"pdf_path4\": range(4, 13),\n",
    "    \"pdf_path5\": range(2, 5),\n",
    "}\n",
    "\n",
    "# Select example number\n",
    "n_example = 3\n",
    "key = f\"pdf_path{n_example}\"\n",
    "path = examples[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "2e7051cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1\n",
      "Fundamentals\n",
      "of deep learning\n",
      "C hapters 1–4 of this book will give you a foundational understanding of\n",
      "what deep learning is, what it can achieve, and how it works. It will also make you\n",
      "familiar with the canonical workflow for solving data problems using deep learn-\n",
      "ing. If you aren’t alread\n",
      "\n",
      "\n",
      "\n",
      "vii\n",
      "contents\n",
      "preface\n",
      "xiii\n",
      "acknowledgments\n",
      "xv\n",
      "about this book\n",
      "xvi\n",
      "about the author\n",
      "xx\n",
      "about the cover\n"
     ]
    }
   ],
   "source": [
    "text, pages_data, start_chapter = process_pdf(path)\n",
    "pages_data_corrected = pages_data[start_chapter:]\n",
    "toc = extract_pages_range(path, content_page_ranges[key])\n",
    "print(text[:300])\n",
    "print('\\n\\n')\n",
    "print(toc[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392cb50c",
   "metadata": {},
   "source": [
    "### Extract chapters & chunck them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "f32d8bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use prompt optimized for gemma3\n",
      "[RunPod] Job started: 978bd049-a800-46a2-85d3-f948da0a44ca-e1\n",
      "[RunPod] Status: IN_QUEUE\n",
      "[RunPod] Status: IN_QUEUE\n",
      "[RunPod] Status: IN_QUEUE\n",
      "[RunPod] Status: IN_QUEUE\n",
      "[RunPod] Status: IN_QUEUE\n",
      "[RunPod] Status: IN_PROGRESS\n",
      "[RunPod] Status: IN_PROGRESS\n",
      "[RunPod] Status: IN_PROGRESS\n",
      "[RunPod] Status: IN_PROGRESS\n",
      "[RunPod] Status: IN_PROGRESS\n",
      "[RunPod] Status: IN_PROGRESS\n",
      "[RunPod] Status: COMPLETED\n"
     ]
    }
   ],
   "source": [
    "chapters_json = extract_chapters_from_toc(toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "4604e04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chapters = extract_chapters(chapters_json, pages_data_corrected)\n",
    "chapters = chapters_chunking(chapters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8274b882",
   "metadata": {},
   "source": [
    "### Random sampling of chapter chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "1d352374",
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter_number = 4\n",
    "n_questions = 5\n",
    "\n",
    "chapter_context = get_chapter_context(chapters, chapter_number, n_questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4871d977",
   "metadata": {},
   "source": [
    "### Set up Chroma and chunk text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "308ebcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL = \"all-MiniLM-L6-v2\"  \n",
    "client, embedding_func = initialize_chromadb(EMBEDDING_MODEL)\n",
    "\n",
    "# Create two collections with different purposes\n",
    "whole_text_collection = initialize_collection(client, embedding_func, \"whole_text_chunks\")\n",
    "update_collection(whole_text_collection, text, max_words=200, min_words=100, overlap_sentences=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "036ec1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_collection(whole_text_collection, text, max_words=200, min_words=100, overlap_sentences=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "132da6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'data preparation and analysis'\n",
    "query_context = query_collection(whole_text_collection, query=query, nresults=3, context_multiplier=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "9ac04ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(query_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "62081923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chapter_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe83e805",
   "metadata": {},
   "source": [
    "### Create prompts for question generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dd8777",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = chapter_prompt(query_context, 5)\n",
    "out2 = chapter_prompt_edgecase(query_context, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "57c447fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start_of_turn>user\n",
      "Generate 5 questions from the following grouped contexts. You may use one or multiple contexts per question.\n",
      "\n",
      "REQUIREMENTS:\n",
      "1. Output valid JSON array format\n",
      "2. Generate EXACTLY 5 questions\n",
      "3. Each answer must be found in the provided contexts\n",
      "4. Create diverse question types\n",
      "5. Reference which context group(s) you used\n",
      "\n",
      "CONTEXT GROUPS:\n",
      "Context 1:\n",
      "The data you’ll manipulate will almost always fall into one of the fol-\n",
      "lowing categories:\n",
      "Vector data—2D tensors of shape (samples, features)\n",
      "Timeseries data or sequence data—3D tensors of shape (samples, timesteps,\n",
      "features)\n",
      "Images—4D tensors of shape (samples, height, width, channels) or (samples,\n",
      "channels, height, width)\n",
      "Video—5D tensors of shape (samples, frames, height, width, channels) or\n",
      "(samples, frames, channels, height, width)\n",
      "2.2.9\n",
      "Vector data\n",
      "This is the most common case. In such a dataset, each single data point can be encoded\n",
      "as a vector, and thus a batch of data will be encoded as a 2D tensor (that is, an array of\n",
      "vectors), where the first axis is the samples axis and the second axis is the features axis. Let’s take a look at two examples:\n",
      "An actuarial dataset of people, where we consider each person’s age, ZIP code,\n",
      "and income. Each person can be characterized as a vector of 3 values, and thus\n",
      "an entire dataset of 100,000 people can be stored in a 2D tensor of shape\n",
      "(100000, 3).\n",
      "\n",
      "Context 2:\n",
      "We’ve previously reviewed three common evaluation protocols:\n",
      "Maintaining a hold-out validation set—The way to go when you have plenty of\n",
      "data\n",
      "Doing K-fold cross-validation—The right choice when you have too few samples\n",
      "for hold-out validation to be reliable\n",
      "Doing iterated K-fold validation—For performing highly accurate model evalua-\n",
      "tion when little data is available\n",
      "Just pick one of these. In most cases, the first will work well enough. 4.5.4\n",
      "Preparing your data\n",
      "Once you know what you’re training on, what you’re optimizing for, and how to evalu-\n",
      "ate your approach, you’re almost ready to begin training models. But first, you should\n",
      "format your data in a way that can be fed into a machine-learning model—here, we’ll\n",
      "assume a deep neural network:\n",
      "As you saw previously, your data should be formatted as tensors. The values taken by these tensors should usually be scaled to small values: for\n",
      "example, in the [-1, 1] range or [0, 1] range. Licensed to   <null>\n",
      "\n",
      "113\n",
      "The universal workflow of machine learning\n",
      "If different features take values in different ranges (heterogeneous data), then\n",
      "the data should be normalized. You may want to do some feature engineering, especially for small-data problems.\n",
      "\n",
      "Context 3:\n",
      "Redundancy in your data—If some data points in your data appear twice (fairly\n",
      "common with real-world data), then shuffling the data and splitting it into a\n",
      "training set and a validation set will result in redundancy between the training\n",
      "and validation sets. In effect, you’ll be testing on part of your training data,\n",
      "which is the worst thing you can do! Make sure your training set and validation\n",
      "set are disjoint. Validation score: \n",
      "average of the \n",
      "validation scores \n",
      "of the k folds\n",
      "Trains the final \n",
      "model on all non-\n",
      "test data available\n",
      "Licensed to   <null>\n",
      "\n",
      "101\n",
      "Data preprocessing, feature engineering, and feature learning\n",
      "4.3\n",
      "Data preprocessing, feature engineering, \n",
      "and feature learning\n",
      "In addition to model evaluation, an important question we must tackle before we dive\n",
      "deeper into model development is the following: how do you prepare the input data\n",
      "and targets before feeding them into a neural network? Many data-preprocessing and\n",
      "feature-engineering techniques are domain specific (for example, specific to text data\n",
      "or image data); we’ll cover those in the following chapters as we encounter them in\n",
      "practical examples. For now, we’ll review the basics that are common to all data\n",
      "domains.\n",
      "\n",
      "OUTPUT FORMAT - Return ONLY this JSON structure:\n",
      "[\n",
      "{\"question\": \"Question text?\", \"answer\": \"Answer text\", \"context_used\": [1, 2]},\n",
      "{\"question\": \"Question text?\", \"answer\": \"Answer text\", \"context_used\": [1]}\n",
      "]\n",
      "\n",
      "Generate the questions:<end_of_turn>\n",
      "<start_of_turn>model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "e8ef36ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "out3 = book_prompt(query_context, num_questions=3, user_query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15860d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
