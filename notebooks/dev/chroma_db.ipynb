{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8286ea1d",
   "metadata": {},
   "source": [
    "### Test splitting on chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3d74256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "sys.path.append(\"../../app/backend\")  \n",
    "import runpod_client\n",
    "import raw_text_processing\n",
    "import text_processing\n",
    "import chunks_processing\n",
    "import messages_templates\n",
    "from raw_text_processing import process_pdf\n",
    "\n",
    "# importlib.reload(toc_parser)\n",
    "# importlib.reload(raw_text_processing)\n",
    "# importlib.reload(text_processing)\n",
    "# importlib.reload(chromadb_utils)\n",
    "# importlib.reload(chunks_processing)\n",
    "# importlib.reload(messages_templates)\n",
    "\n",
    "# from raw_text_processing import process_pdf, extract_pages_range, extract_chapters\n",
    "# from text_processing import text_chunking, chapters_chunking\n",
    "# from chromadb_utils import initialize_chromadb, initialize_collection, update_collection\n",
    "# from chunks_processing import query_collection, get_chapter_context\n",
    "# from messages_templates import chapter_prompt, chapter_prompt_edgecase, book_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d92ac5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary mapping example keys to PDF paths\n",
    "examples = {\n",
    "    \"pdf_path1\": \"../../data/mcelreath_2020_statistical-rethinking.pdf\",\n",
    "    \"pdf_path2\": \"../../data/Theory of Statistic.pdf\",\n",
    "    \"pdf_path3\": \"../../data/Deep Learning with Python.pdf\",\n",
    "    \"pdf_path4\": \"../../data/Natural_Image_Statistics.pdf\",\n",
    "    \"pdf_path5\": \"../../data/mml-book.pdf\"\n",
    "}\n",
    "\n",
    "# Dictionary mapping example keys to page ranges to extract content from\n",
    "content_page_ranges = {\n",
    "    \"pdf_path1\": range(5, 8),\n",
    "    \"pdf_path2\": range(10, 17),\n",
    "    \"pdf_path3\": range(7, 13),\n",
    "    \"pdf_path4\": range(4, 13),\n",
    "    \"pdf_path5\": range(2, 5),\n",
    "}\n",
    "\n",
    "# Select example number\n",
    "n_example = 3\n",
    "key = f\"pdf_path{n_example}\"\n",
    "path = examples[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d704e202",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "process_pdf() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mprocess_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: process_pdf() takes 0 positional arguments but 1 was given"
     ]
    }
   ],
   "source": [
    "process_pdf(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e7051cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'process_pdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m text, pages_data, start_chapter \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_pdf\u001b[49m(path)\n\u001b[1;32m      2\u001b[0m pages_data_corrected \u001b[38;5;241m=\u001b[39m pages_data[start_chapter:]\n\u001b[1;32m      3\u001b[0m toc \u001b[38;5;241m=\u001b[39m extract_pages_range(path, content_page_ranges[key])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'process_pdf' is not defined"
     ]
    }
   ],
   "source": [
    "text, pages_data, start_chapter = process_pdf(path)\n",
    "pages_data_corrected = pages_data[start_chapter:]\n",
    "toc = extract_pages_range(path, content_page_ranges[key])\n",
    "print(text[:300])\n",
    "print('\\n\\n')\n",
    "print(toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392cb50c",
   "metadata": {},
   "source": [
    "### Extract chapters & chunck them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "f32d8bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use prompt optimized for gemma3\n",
      "[RunPod] Job started: 978bd049-a800-46a2-85d3-f948da0a44ca-e1\n",
      "[RunPod] Status: IN_QUEUE\n",
      "[RunPod] Status: IN_QUEUE\n",
      "[RunPod] Status: IN_QUEUE\n",
      "[RunPod] Status: IN_QUEUE\n",
      "[RunPod] Status: IN_QUEUE\n",
      "[RunPod] Status: IN_PROGRESS\n",
      "[RunPod] Status: IN_PROGRESS\n",
      "[RunPod] Status: IN_PROGRESS\n",
      "[RunPod] Status: IN_PROGRESS\n",
      "[RunPod] Status: IN_PROGRESS\n",
      "[RunPod] Status: IN_PROGRESS\n",
      "[RunPod] Status: COMPLETED\n"
     ]
    }
   ],
   "source": [
    "chapters_json = extract_chapters_from_toc(toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfb4ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chapters_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "4604e04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chapters = extract_chapters(chapters_json, pages_data_corrected)\n",
    "chapters = chapters_chunking(chapters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8274b882",
   "metadata": {},
   "source": [
    "### Random sampling of chapter chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "1d352374",
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter_number = 4\n",
    "n_questions = 5\n",
    "\n",
    "chapter_context = get_chapter_context(chapters, chapter_number, n_questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4871d977",
   "metadata": {},
   "source": [
    "### Set up Chroma and chunk text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "308ebcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL = \"all-MiniLM-L6-v2\"  \n",
    "client, embedding_func = initialize_chromadb(EMBEDDING_MODEL)\n",
    "\n",
    "# Create two collections with different purposes\n",
    "whole_text_collection = initialize_collection(client, embedding_func, \"whole_text_chunks\")\n",
    "update_collection(whole_text_collection, text, max_words=200, min_words=100, overlap_sentences=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "036ec1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_collection(whole_text_collection, text, max_words=200, min_words=100, overlap_sentences=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "132da6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'data preparation and analysis'\n",
    "query_context = query_collection(whole_text_collection, query=query, nresults=3, context_multiplier=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe83e805",
   "metadata": {},
   "source": [
    "### Create prompts for question generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "b9dd8777",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = chapter_prompt(chapter_context, 5)\n",
    "out2 = chapter_prompt_edgecase(chapter_context, 5)\n",
    "out3 = book_prompt(query_context, num_questions=3, user_query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "a15860d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RunPod] Job started: 049a65ff-4017-4857-b55c-34f31ede75d0-e1\n",
      "[RunPod] Status: IN_QUEUE\n",
      "[RunPod] Status: IN_QUEUE\n",
      "[RunPod] Status: IN_QUEUE\n",
      "[RunPod] Status: IN_QUEUE\n",
      "[RunPod] Status: IN_PROGRESS\n",
      "[RunPod] Status: IN_PROGRESS\n",
      "[RunPod] Status: IN_PROGRESS\n",
      "[RunPod] Status: IN_PROGRESS\n",
      "[RunPod] Status: IN_PROGRESS\n",
      "[RunPod] Status: COMPLETED\n"
     ]
    }
   ],
   "source": [
    "questions = run_prompt(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "3fad50f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "[\n",
      "{\"question\": \"What is the purpose of preprocess_input in the context of visualizing filters?\", \"answer\": \"preprocess_input is used to normalize the input image tensor according to the specific requirements of the VGG16 model, ensuring that the model receives input data in the expected format.\"},\n",
      "{\"question\": \"What does the 'block5_conv3' layer represent in the VGG16 model, and why is it targeted for Grad-CAM?\", \"answer\": \"block5_conv3 is the last convolutional layer in the VGG16 model. It is targeted for Grad-CAM because it's closer to the final classification layer and captures higher-level features, enabling better localization of important image regions.\"},\n",
      "{\"question\": \"How does the deprocess_image function transform a tensor into a displayable image?\", \"answer\": \"The deprocess_image function performs several steps: it centers the tensor around 0, normalizes it, clips values to [0, 1], scales it, and finally converts it to an 8-bit unsigned integer format (uint8) within the range [0, 255] to create a valid RGB image.\"},\n",
      "{\"question\": \"What is the function of the `generate_pattern` function, and what inputs does it take?\", \"answer\": \"The `generate_pattern` function aims to generate an image pattern that maximizes the activation of a specific filter in a given layer of the neural network. It takes the layer name and filter index as inputs, along with an optional size parameter for the generated pattern.\"},\n",
      "{\"question\": \"How does the stochastic gradient descent process work within the `generate_pattern` function?\", \"answer\": \"The stochastic gradient descent process starts with a random image, then iteratively adjusts the image in the direction that maximizes the filter's activation by computing the gradient of the loss (filter activation) with respect to the input image, and then applying that gradient to update the image.\"}\n",
      "]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c045cd01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
