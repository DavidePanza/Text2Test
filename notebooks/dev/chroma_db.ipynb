{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8286ea1d",
   "metadata": {},
   "source": [
    "### Test splitting on chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "b3d74256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "sys.path.append(\"../../src\")  \n",
    "import toc_parser\n",
    "import raw_text_processing\n",
    "import text_processing\n",
    "import chromadb_utils\n",
    "import chunks_processing\n",
    "\n",
    "importlib.reload(toc_parser)\n",
    "importlib.reload(raw_text_processing)\n",
    "importlib.reload(text_processing)\n",
    "importlib.reload(chromadb_utils)\n",
    "importlib.reload(chunks_processing)\n",
    "\n",
    "from raw_text_processing import process_pdf, extract_pages_range, extract_chapters\n",
    "from toc_parser import extract_chapters_from_toc\n",
    "from text_processing import text_chunking, chapters_chunking\n",
    "from chromadb_utils import initialize_chromadb, initialize_collection, update_collection\n",
    "from chunks_processing import query_collection, get_chapter_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "d92ac5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary mapping example keys to PDF paths\n",
    "examples = {\n",
    "    \"pdf_path1\": \"../../data/mcelreath_2020_statistical-rethinking.pdf\",\n",
    "    \"pdf_path2\": \"../../data/Theory of Statistic.pdf\",\n",
    "    \"pdf_path3\": \"../../data/Deep Learning with Python.pdf\",\n",
    "    \"pdf_path4\": \"../../data/Natural_Image_Statistics.pdf\",\n",
    "    \"pdf_path5\": \"../../data/mml-book.pdf\"\n",
    "}\n",
    "\n",
    "# Dictionary mapping example keys to page ranges to extract content from\n",
    "content_page_ranges = {\n",
    "    \"pdf_path1\": range(5, 8),\n",
    "    \"pdf_path2\": range(10, 17),\n",
    "    \"pdf_path3\": range(7, 13),\n",
    "    \"pdf_path4\": range(4, 13),\n",
    "    \"pdf_path5\": range(2, 5),\n",
    "}\n",
    "\n",
    "# Select example number\n",
    "n_example = 3\n",
    "key = f\"pdf_path{n_example}\"\n",
    "path = examples[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "2e7051cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1\n",
      "Fundamentals\n",
      "of deep learning\n",
      "C hapters 1–4 of this book will give you a foundational understanding of\n",
      "what deep learning is, what it can achieve, and how it works. It will also make you\n",
      "familiar with the canonical workflow for solving data problems using deep learn-\n",
      "ing. If you aren’t alread\n",
      "\n",
      "\n",
      "\n",
      "vii\n",
      "contents\n",
      "preface\n",
      "xiii\n",
      "acknowledgments\n",
      "xv\n",
      "about this book\n",
      "xvi\n",
      "about the author\n",
      "xx\n",
      "about the cover\n"
     ]
    }
   ],
   "source": [
    "text, pages_data, start_chapter = process_pdf(path)\n",
    "pages_data_corrected = pages_data[start_chapter:]\n",
    "toc = extract_pages_range(path, content_page_ranges[key])\n",
    "print(text[:300])\n",
    "print('\\n\\n')\n",
    "print(toc[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392cb50c",
   "metadata": {},
   "source": [
    "### Extract chapters & chunck them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "f32d8bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use prompt optimized for gemma3\n",
      "[RunPod] Job started: 978bd049-a800-46a2-85d3-f948da0a44ca-e1\n",
      "[RunPod] Status: IN_QUEUE\n",
      "[RunPod] Status: IN_QUEUE\n",
      "[RunPod] Status: IN_QUEUE\n",
      "[RunPod] Status: IN_QUEUE\n",
      "[RunPod] Status: IN_QUEUE\n",
      "[RunPod] Status: IN_PROGRESS\n",
      "[RunPod] Status: IN_PROGRESS\n",
      "[RunPod] Status: IN_PROGRESS\n",
      "[RunPod] Status: IN_PROGRESS\n",
      "[RunPod] Status: IN_PROGRESS\n",
      "[RunPod] Status: IN_PROGRESS\n",
      "[RunPod] Status: COMPLETED\n"
     ]
    }
   ],
   "source": [
    "chapters_json = extract_chapters_from_toc(toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "4604e04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chapters = extract_chapters(chapters_json, pages_data_corrected)\n",
    "chapters = chapters_chunking(chapters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8274b882",
   "metadata": {},
   "source": [
    "### Random sampling of chapter chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "1d352374",
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter_number = 4\n",
    "n_questions = 400\n",
    "\n",
    "chapter_context = get_chapter_context(chapters, chapter_number, n_questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4871d977",
   "metadata": {},
   "source": [
    "### Set up Chroma and chunk text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "308ebcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL = \"all-MiniLM-L6-v2\"  \n",
    "client, embedding_func = initialize_chromadb(EMBEDDING_MODEL)\n",
    "\n",
    "# Create two collections with different purposes\n",
    "whole_text_collection = initialize_collection(client, embedding_func, \"whole_text_chunks\")\n",
    "update_collection(whole_text_collection, text, max_words=200, min_words=100, overlap_sentences=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "036ec1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_collection(whole_text_collection, text, max_words=200, min_words=100, overlap_sentences=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "132da6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_context = query_collection(whole_text_collection, query='data preparation', nresults=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62081923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The data you’ll manipulate will almost always fall into one of the fol-\\nlowing categories:\\n\\uf0a1Vector data—2D tensors of shape (samples, features)\\n\\uf0a1Timeseries data or sequence data—3D tensors of shape (samples, timesteps,\\nfeatures)\\n\\uf0a1Images—4D tensors of shape (samples, height, width, channels) or (samples,\\nchannels, height, width)\\n\\uf0a1Video—5D tensors of shape (samples, frames, height, width, channels) or\\n(samples, frames, channels, height, width)\\n2.2.9\\nVector data\\nThis is the most common case. In such a dataset, each single data point can be encoded\\nas a vector, and thus a batch of data will be encoded as a 2D tensor (that is, an array of\\nvectors), where the first axis is the samples axis and the second axis is the features axis. Let’s take a look at two examples:\\n\\uf0a1An actuarial dataset of people, where we consider each person’s age, ZIP code,\\nand income. Each person can be characterized as a vector of 3 values, and thus\\nan entire dataset of 100,000 people can be stored in a 2D tensor of shape\\n(100000, 3).',\n",
       " 'We’ve previously reviewed three common evaluation protocols:\\n\\uf0a1Maintaining a hold-out validation set—The way to go when you have plenty of\\ndata\\n\\uf0a1Doing K-fold cross-validation—The right choice when you have too few samples\\nfor hold-out validation to be reliable\\n\\uf0a1Doing iterated K-fold validation—For performing highly accurate model evalua-\\ntion when little data is available\\nJust pick one of these. In most cases, the first will work well enough. 4.5.4\\nPreparing your data\\nOnce you know what you’re training on, what you’re optimizing for, and how to evalu-\\nate your approach, you’re almost ready to begin training models. But first, you should\\nformat your data in a way that can be fed into a machine-learning model—here, we’ll\\nassume a deep neural network:\\n\\uf0a1As you saw previously, your data should be formatted as tensors. \\uf0a1The values taken by these tensors should usually be scaled to small values: for\\nexample, in the [-1, 1] range or [0, 1] range. Licensed to   <null>\\n\\n113\\nThe universal workflow of machine learning\\n\\uf0a1If different features take values in different ranges (heterogeneous data), then\\nthe data should be normalized. \\uf0a1You may want to do some feature engineering, especially for small-data problems.',\n",
       " '\\uf0a1Redundancy in your data—If some data points in your data appear twice (fairly\\ncommon with real-world data), then shuffling the data and splitting it into a\\ntraining set and a validation set will result in redundancy between the training\\nand validation sets. In effect, you’ll be testing on part of your training data,\\nwhich is the worst thing you can do! Make sure your training set and validation\\nset are disjoint. Validation score: \\naverage of the \\nvalidation scores \\nof the k folds\\nTrains the final \\nmodel on all non-\\ntest data available\\nLicensed to   <null>\\n\\n101\\nData preprocessing, feature engineering, and feature learning\\n4.3\\nData preprocessing, feature engineering, \\nand feature learning\\nIn addition to model evaluation, an important question we must tackle before we dive\\ndeeper into model development is the following: how do you prepare the input data\\nand targets before feeding them into a neural network? Many data-preprocessing and\\nfeature-engineering techniques are domain specific (for example, specific to text data\\nor image data); we’ll cover those in the following chapters as we encounter them in\\npractical examples. For now, we’ll review the basics that are common to all data\\ndomains.']"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe83e805",
   "metadata": {},
   "source": [
    "### Create prompts for question generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f36f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gemma_prompt(contexts, num_questions, max_questions=5):\n",
    "    \"\"\"\n",
    "    Create a prompt formatted for Gemma 3 12B-IT model.\n",
    "    This prompt is designed to generate diverse questions based on provided text contexts.\n",
    "    Args:\n",
    "        contexts (list): List of text contexts to base questions on.\n",
    "        num_questions (int): Number of questions to generate.\n",
    "        max_questions (int): Maximum number of questions allowed.  \n",
    "    Returns:\n",
    "        str: Formatted prompt string for Gemma 3 model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Gemma uses special tokens for instruction tuning\n",
    "    prompt = \"\"\"<start_of_turn>user\n",
    "You are a question generation expert. Generate exactly {num_questions} diverse questions based on the provided text contexts.\n",
    "\n",
    "IMPORTANT REQUIREMENTS:\n",
    "1. Output MUST be valid JSON format\n",
    "2. Generate EXACTLY {num_questions} questions\n",
    "3. Each question must have a complete answer from the contexts\n",
    "4. Vary question types (what, why, how, when, explain, compare)\n",
    "5. Do not generate yes/no questions\n",
    "6. Answers should be 1-3 sentences long\n",
    "\n",
    "CONTEXTS:\n",
    "{contexts}\n",
    "\n",
    "OUTPUT FORMAT - Return ONLY valid JSON array:\n",
    "[\n",
    "{{\"question\": \"Your question here?\", \"answer\": \"Complete answer from the context\"}},\n",
    "{{\"question\": \"Another question?\", \"answer\": \"Another answer\"}}\n",
    "]\n",
    "\n",
    "Generate the questions now:<end_of_turn>\n",
    "<start_of_turn>model\n",
    "\"\"\".format(\n",
    "        num_questions=min(num_questions, max_questions),\n",
    "        contexts=format_contexts(contexts)\n",
    "    )\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "def create_gemma_prompt_grouped(grouped_chunks, num_questions, max_questions=5):\n",
    "    \"\"\"\n",
    "    This prompt is designed to handle edge cases where contexts retrieved are less than the number of questions requested.\n",
    "    Args:\n",
    "        contexts (list): List of text contexts to format.\n",
    "    Returns:\n",
    "        str: Formatted string of contexts.\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = \"\"\"<start_of_turn>user\n",
    "Generate {num_questions} questions from the following contexts. You may:\n",
    "- Generate one or more questions from each context\n",
    "- Use multiple contexts for a single question\n",
    "- Skip contexts if they don't contain meaningful information\n",
    "\n",
    "REQUIREMENTS:\n",
    "1. Output valid JSON array format\n",
    "2. Generate EXACTLY {num_questions} questions\n",
    "3. Each answer must be found in the provided contexts\n",
    "4. Create diverse question types\n",
    "5. Reference which context group(s) you used\n",
    "\n",
    "CONTEXT GROUPS:\n",
    "{context_groups}\n",
    "\n",
    "OUTPUT FORMAT - Return ONLY this JSON structure:\n",
    "[\n",
    "{{\"question\": \"Question text?\", \"answer\": \"Answer text\", \"context_used\": [1, 2]}},\n",
    "{{\"question\": \"Question text?\", \"answer\": \"Answer text\", \"context_used\": [1]}}\n",
    "]\n",
    "\n",
    "Generate the questions:<end_of_turn>\n",
    "<start_of_turn>model\n",
    "\"\"\".format(\n",
    "        num_questions=min(num_questions, max_questions),\n",
    "        context_groups=format_contexts(grouped_chunks)\n",
    "    )\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "def format_contexts(contexts):\n",
    "    \"\"\"\n",
    "    Format contexts for better readability.\n",
    "    \"\"\"\n",
    "    formatted = \"\"\n",
    "    for i, context in enumerate(contexts, 1):\n",
    "        formatted += f\"Context {i}:\\n{context.strip()}\\n\\n\"\n",
    "    return formatted.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "b9dd8777",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = create_gemma_prompt(query_context, 5)\n",
    "out2 = create_gemma_prompt_grouped(query_context, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "57c447fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start_of_turn>user\n",
      "Generate 5 questions from the following grouped contexts. You may use one or multiple contexts per question.\n",
      "\n",
      "REQUIREMENTS:\n",
      "1. Output valid JSON array format\n",
      "2. Generate EXACTLY 5 questions\n",
      "3. Each answer must be found in the provided contexts\n",
      "4. Create diverse question types\n",
      "5. Reference which context group(s) you used\n",
      "\n",
      "CONTEXT GROUPS:\n",
      "Context 1:\n",
      "The data you’ll manipulate will almost always fall into one of the fol-\n",
      "lowing categories:\n",
      "Vector data—2D tensors of shape (samples, features)\n",
      "Timeseries data or sequence data—3D tensors of shape (samples, timesteps,\n",
      "features)\n",
      "Images—4D tensors of shape (samples, height, width, channels) or (samples,\n",
      "channels, height, width)\n",
      "Video—5D tensors of shape (samples, frames, height, width, channels) or\n",
      "(samples, frames, channels, height, width)\n",
      "2.2.9\n",
      "Vector data\n",
      "This is the most common case. In such a dataset, each single data point can be encoded\n",
      "as a vector, and thus a batch of data will be encoded as a 2D tensor (that is, an array of\n",
      "vectors), where the first axis is the samples axis and the second axis is the features axis. Let’s take a look at two examples:\n",
      "An actuarial dataset of people, where we consider each person’s age, ZIP code,\n",
      "and income. Each person can be characterized as a vector of 3 values, and thus\n",
      "an entire dataset of 100,000 people can be stored in a 2D tensor of shape\n",
      "(100000, 3).\n",
      "\n",
      "Context 2:\n",
      "We’ve previously reviewed three common evaluation protocols:\n",
      "Maintaining a hold-out validation set—The way to go when you have plenty of\n",
      "data\n",
      "Doing K-fold cross-validation—The right choice when you have too few samples\n",
      "for hold-out validation to be reliable\n",
      "Doing iterated K-fold validation—For performing highly accurate model evalua-\n",
      "tion when little data is available\n",
      "Just pick one of these. In most cases, the first will work well enough. 4.5.4\n",
      "Preparing your data\n",
      "Once you know what you’re training on, what you’re optimizing for, and how to evalu-\n",
      "ate your approach, you’re almost ready to begin training models. But first, you should\n",
      "format your data in a way that can be fed into a machine-learning model—here, we’ll\n",
      "assume a deep neural network:\n",
      "As you saw previously, your data should be formatted as tensors. The values taken by these tensors should usually be scaled to small values: for\n",
      "example, in the [-1, 1] range or [0, 1] range. Licensed to   <null>\n",
      "\n",
      "113\n",
      "The universal workflow of machine learning\n",
      "If different features take values in different ranges (heterogeneous data), then\n",
      "the data should be normalized. You may want to do some feature engineering, especially for small-data problems.\n",
      "\n",
      "Context 3:\n",
      "Redundancy in your data—If some data points in your data appear twice (fairly\n",
      "common with real-world data), then shuffling the data and splitting it into a\n",
      "training set and a validation set will result in redundancy between the training\n",
      "and validation sets. In effect, you’ll be testing on part of your training data,\n",
      "which is the worst thing you can do! Make sure your training set and validation\n",
      "set are disjoint. Validation score: \n",
      "average of the \n",
      "validation scores \n",
      "of the k folds\n",
      "Trains the final \n",
      "model on all non-\n",
      "test data available\n",
      "Licensed to   <null>\n",
      "\n",
      "101\n",
      "Data preprocessing, feature engineering, and feature learning\n",
      "4.3\n",
      "Data preprocessing, feature engineering, \n",
      "and feature learning\n",
      "In addition to model evaluation, an important question we must tackle before we dive\n",
      "deeper into model development is the following: how do you prepare the input data\n",
      "and targets before feeding them into a neural network? Many data-preprocessing and\n",
      "feature-engineering techniques are domain specific (for example, specific to text data\n",
      "or image data); we’ll cover those in the following chapters as we encounter them in\n",
      "practical examples. For now, we’ll review the basics that are common to all data\n",
      "domains.\n",
      "\n",
      "OUTPUT FORMAT - Return ONLY this JSON structure:\n",
      "[\n",
      "{\"question\": \"Question text?\", \"answer\": \"Answer text\", \"context_used\": [1, 2]},\n",
      "{\"question\": \"Question text?\", \"answer\": \"Answer text\", \"context_used\": [1]}\n",
      "]\n",
      "\n",
      "Generate the questions:<end_of_turn>\n",
      "<start_of_turn>model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e4fc59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
