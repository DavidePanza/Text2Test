{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8286ea1d",
   "metadata": {},
   "source": [
    "### Test splitting on chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "b3d74256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "sys.path.append(\"../../src\")  \n",
    "import toc_parser\n",
    "import raw_text_processing\n",
    "import text_processing\n",
    "import chromadb_utils\n",
    "import chunks_processing\n",
    "\n",
    "importlib.reload(toc_parser)\n",
    "importlib.reload(raw_text_processing)\n",
    "importlib.reload(text_processing)\n",
    "importlib.reload(chromadb_utils)\n",
    "importlib.reload(chunks_processing)\n",
    "\n",
    "from raw_text_processing import process_pdf, extract_pages_range, extract_chapters\n",
    "from toc_parser import extract_chapters_from_toc\n",
    "from text_processing import text_chunking, chapters_chunking\n",
    "from chromadb_utils import initialize_chromadb, initialize_collection, update_collection\n",
    "from chunks_processing import query_collection, get_chapter_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "d92ac5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary mapping example keys to PDF paths\n",
    "examples = {\n",
    "    \"pdf_path1\": \"../../data/mcelreath_2020_statistical-rethinking.pdf\",\n",
    "    \"pdf_path2\": \"../../data/Theory of Statistic.pdf\",\n",
    "    \"pdf_path3\": \"../../data/Deep Learning with Python.pdf\",\n",
    "    \"pdf_path4\": \"../../data/Natural_Image_Statistics.pdf\",\n",
    "    \"pdf_path5\": \"../../data/mml-book.pdf\"\n",
    "}\n",
    "\n",
    "# Dictionary mapping example keys to page ranges to extract content from\n",
    "content_page_ranges = {\n",
    "    \"pdf_path1\": range(5, 8),\n",
    "    \"pdf_path2\": range(10, 17),\n",
    "    \"pdf_path3\": range(7, 13),\n",
    "    \"pdf_path4\": range(4, 13),\n",
    "    \"pdf_path5\": range(2, 5),\n",
    "}\n",
    "\n",
    "# Select example number\n",
    "n_example = 3\n",
    "key = f\"pdf_path{n_example}\"\n",
    "path = examples[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "2e7051cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1\n",
      "Fundamentals\n",
      "of deep learning\n",
      "C hapters 1–4 of this book will give you a foundational understanding of\n",
      "what deep learning is, what it can achieve, and how it works. It will also make you\n",
      "familiar with the canonical workflow for solving data problems using deep learn-\n",
      "ing. If you aren’t alread\n",
      "\n",
      "\n",
      "\n",
      "vii\n",
      "contents\n",
      "preface\n",
      "xiii\n",
      "acknowledgments\n",
      "xv\n",
      "about this book\n",
      "xvi\n",
      "about the author\n",
      "xx\n",
      "about the cover\n"
     ]
    }
   ],
   "source": [
    "text, pages_data, start_chapter = process_pdf(path)\n",
    "pages_data_corrected = pages_data[start_chapter:]\n",
    "toc = extract_pages_range(path, content_page_ranges[key])\n",
    "print(text[:300])\n",
    "print('\\n\\n')\n",
    "print(toc[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392cb50c",
   "metadata": {},
   "source": [
    "### Extract chapters & chunck them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "f32d8bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use prompt optimized for gemma3\n",
      "[RunPod] Job started: 978bd049-a800-46a2-85d3-f948da0a44ca-e1\n",
      "[RunPod] Status: IN_QUEUE\n",
      "[RunPod] Status: IN_QUEUE\n",
      "[RunPod] Status: IN_QUEUE\n",
      "[RunPod] Status: IN_QUEUE\n",
      "[RunPod] Status: IN_QUEUE\n",
      "[RunPod] Status: IN_PROGRESS\n",
      "[RunPod] Status: IN_PROGRESS\n",
      "[RunPod] Status: IN_PROGRESS\n",
      "[RunPod] Status: IN_PROGRESS\n",
      "[RunPod] Status: IN_PROGRESS\n",
      "[RunPod] Status: IN_PROGRESS\n",
      "[RunPod] Status: COMPLETED\n"
     ]
    }
   ],
   "source": [
    "chapters_json = extract_chapters_from_toc(toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "4604e04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chapters = extract_chapters(chapters_json, pages_data_corrected)\n",
    "chapters = chapters_chunking(chapters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8274b882",
   "metadata": {},
   "source": [
    "### Random sampling of chapter chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "1d352374",
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter_number = 4\n",
    "n_questions = 5\n",
    "\n",
    "chapter_context = get_chapter_context(chapters, chapter_number, n_questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4871d977",
   "metadata": {},
   "source": [
    "### Set up Chroma and chunk text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "308ebcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL = \"all-MiniLM-L6-v2\"  \n",
    "client, embedding_func = initialize_chromadb(EMBEDDING_MODEL)\n",
    "\n",
    "# Create two collections with different purposes\n",
    "whole_text_collection = initialize_collection(client, embedding_func, \"whole_text_chunks\")\n",
    "update_collection(whole_text_collection, text, max_words=200, min_words=100, overlap_sentences=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "036ec1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_collection(whole_text_collection, text, max_words=200, min_words=100, overlap_sentences=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "132da6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'data preparation and analysis'\n",
    "query_context = query_collection(whole_text_collection, query=query, nresults=3, context_multiplier=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "9ac04ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(query_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "62081923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chapter_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe83e805",
   "metadata": {},
   "source": [
    "### Create prompts for question generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f36f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chapter_prompt(contexts, num_questions, max_questions=5):\n",
    "    \"\"\"\n",
    "    Create a prompt formatted for Gemma 3 12B-IT model.\n",
    "    This prompt is designed to generate diverse questions based on provided text contexts.\n",
    "    Args:\n",
    "        contexts (list): List of text contexts to base questions on.\n",
    "        num_questions (int): Number of questions to generate.\n",
    "        max_questions (int): Maximum number of questions allowed.  \n",
    "    Returns:\n",
    "        str: Formatted prompt string for Gemma 3 model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Gemma uses special tokens for instruction tuning\n",
    "    prompt = \"\"\"<start_of_turn>user\n",
    "You are a question generation expert. Generate exactly {num_questions} diverse questions based on the provided text contexts.\n",
    "\n",
    "IMPORTANT REQUIREMENTS:\n",
    "1. Output MUST be valid JSON format\n",
    "2. Generate EXACTLY {num_questions} questions\n",
    "3. Each question must have a complete answer from the contexts\n",
    "4. Vary question types (what, why, how, when, explain, compare)\n",
    "5. Do not generate yes/no questions\n",
    "6. Answers should be 1-3 sentences long\n",
    "\n",
    "CONTEXTS:\n",
    "{contexts}\n",
    "\n",
    "OUTPUT FORMAT - Return ONLY valid JSON array:\n",
    "[\n",
    "{{\"question\": \"Your question here?\", \"answer\": \"Complete answer from the context\"}},\n",
    "{{\"question\": \"Another question?\", \"answer\": \"Another answer\"}}\n",
    "]\n",
    "\n",
    "Generate the questions now:<end_of_turn>\n",
    "<start_of_turn>model\n",
    "\"\"\".format(\n",
    "        num_questions=min(num_questions, max_questions),\n",
    "        contexts=format_contexts(contexts)\n",
    "    )\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "def chapter_prompt_edgecase(grouped_chunks, num_questions, max_questions=5):\n",
    "    \"\"\"\n",
    "    Create a prompt formatted for Gemma 3 12B-IT model.\n",
    "    This prompt is designed to handle edge cases where contexts retrieved are less than the number of questions requested.\n",
    "    Args:\n",
    "        contexts (list): List of text contexts to format.\n",
    "    Returns:\n",
    "        str: Formatted string of contexts.\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = \"\"\"<start_of_turn>user\n",
    "Generate {num_questions} questions from the following contexts. You may:\n",
    "- Generate one or more questions from each context\n",
    "- Use multiple contexts for a single question\n",
    "- Skip contexts if they don't contain meaningful information\n",
    "\n",
    "REQUIREMENTS:\n",
    "1. Output valid JSON array format\n",
    "2. Generate EXACTLY {num_questions} questions\n",
    "3. Each answer must be found in the provided contexts\n",
    "4. Create diverse question types\n",
    "5. Reference which context group(s) you used\n",
    "\n",
    "CONTEXT GROUPS:\n",
    "{context_groups}\n",
    "\n",
    "OUTPUT FORMAT - Return ONLY this JSON structure:\n",
    "[\n",
    "{{\"question\": \"Question text?\", \"answer\": \"Answer text\", \"context_used\": [1, 2]}},\n",
    "{{\"question\": \"Question text?\", \"answer\": \"Answer text\", \"context_used\": [1]}}\n",
    "]\n",
    "\n",
    "Generate the questions:<end_of_turn>\n",
    "<start_of_turn>model\n",
    "\"\"\".format(\n",
    "        num_questions=min(num_questions, max_questions),\n",
    "        context_groups=format_contexts(grouped_chunks)\n",
    "    )\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "def format_contexts(contexts):\n",
    "    \"\"\"\n",
    "    Format contexts for better readability.\n",
    "    \"\"\"\n",
    "    formatted = \"\"\n",
    "    for i, context in enumerate(contexts, 1):\n",
    "        formatted += f\"Context {i}:\\n{context.strip()}\\n\\n\"\n",
    "    return formatted.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dd8777",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = chapter_prompt(query_context, 5)\n",
    "out2 = chapter_prompt_edgecase(query_context, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "57c447fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start_of_turn>user\n",
      "Generate 5 questions from the following grouped contexts. You may use one or multiple contexts per question.\n",
      "\n",
      "REQUIREMENTS:\n",
      "1. Output valid JSON array format\n",
      "2. Generate EXACTLY 5 questions\n",
      "3. Each answer must be found in the provided contexts\n",
      "4. Create diverse question types\n",
      "5. Reference which context group(s) you used\n",
      "\n",
      "CONTEXT GROUPS:\n",
      "Context 1:\n",
      "The data you’ll manipulate will almost always fall into one of the fol-\n",
      "lowing categories:\n",
      "Vector data—2D tensors of shape (samples, features)\n",
      "Timeseries data or sequence data—3D tensors of shape (samples, timesteps,\n",
      "features)\n",
      "Images—4D tensors of shape (samples, height, width, channels) or (samples,\n",
      "channels, height, width)\n",
      "Video—5D tensors of shape (samples, frames, height, width, channels) or\n",
      "(samples, frames, channels, height, width)\n",
      "2.2.9\n",
      "Vector data\n",
      "This is the most common case. In such a dataset, each single data point can be encoded\n",
      "as a vector, and thus a batch of data will be encoded as a 2D tensor (that is, an array of\n",
      "vectors), where the first axis is the samples axis and the second axis is the features axis. Let’s take a look at two examples:\n",
      "An actuarial dataset of people, where we consider each person’s age, ZIP code,\n",
      "and income. Each person can be characterized as a vector of 3 values, and thus\n",
      "an entire dataset of 100,000 people can be stored in a 2D tensor of shape\n",
      "(100000, 3).\n",
      "\n",
      "Context 2:\n",
      "We’ve previously reviewed three common evaluation protocols:\n",
      "Maintaining a hold-out validation set—The way to go when you have plenty of\n",
      "data\n",
      "Doing K-fold cross-validation—The right choice when you have too few samples\n",
      "for hold-out validation to be reliable\n",
      "Doing iterated K-fold validation—For performing highly accurate model evalua-\n",
      "tion when little data is available\n",
      "Just pick one of these. In most cases, the first will work well enough. 4.5.4\n",
      "Preparing your data\n",
      "Once you know what you’re training on, what you’re optimizing for, and how to evalu-\n",
      "ate your approach, you’re almost ready to begin training models. But first, you should\n",
      "format your data in a way that can be fed into a machine-learning model—here, we’ll\n",
      "assume a deep neural network:\n",
      "As you saw previously, your data should be formatted as tensors. The values taken by these tensors should usually be scaled to small values: for\n",
      "example, in the [-1, 1] range or [0, 1] range. Licensed to   <null>\n",
      "\n",
      "113\n",
      "The universal workflow of machine learning\n",
      "If different features take values in different ranges (heterogeneous data), then\n",
      "the data should be normalized. You may want to do some feature engineering, especially for small-data problems.\n",
      "\n",
      "Context 3:\n",
      "Redundancy in your data—If some data points in your data appear twice (fairly\n",
      "common with real-world data), then shuffling the data and splitting it into a\n",
      "training set and a validation set will result in redundancy between the training\n",
      "and validation sets. In effect, you’ll be testing on part of your training data,\n",
      "which is the worst thing you can do! Make sure your training set and validation\n",
      "set are disjoint. Validation score: \n",
      "average of the \n",
      "validation scores \n",
      "of the k folds\n",
      "Trains the final \n",
      "model on all non-\n",
      "test data available\n",
      "Licensed to   <null>\n",
      "\n",
      "101\n",
      "Data preprocessing, feature engineering, and feature learning\n",
      "4.3\n",
      "Data preprocessing, feature engineering, \n",
      "and feature learning\n",
      "In addition to model evaluation, an important question we must tackle before we dive\n",
      "deeper into model development is the following: how do you prepare the input data\n",
      "and targets before feeding them into a neural network? Many data-preprocessing and\n",
      "feature-engineering techniques are domain specific (for example, specific to text data\n",
      "or image data); we’ll cover those in the following chapters as we encounter them in\n",
      "practical examples. For now, we’ll review the basics that are common to all data\n",
      "domains.\n",
      "\n",
      "OUTPUT FORMAT - Return ONLY this JSON structure:\n",
      "[\n",
      "{\"question\": \"Question text?\", \"answer\": \"Answer text\", \"context_used\": [1, 2]},\n",
      "{\"question\": \"Question text?\", \"answer\": \"Answer text\", \"context_used\": [1]}\n",
      "]\n",
      "\n",
      "Generate the questions:<end_of_turn>\n",
      "<start_of_turn>model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "78e4fc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def book_prompt(contexts, num_questions, user_query=None, max_questions=5):\n",
    "    \"\"\"\n",
    "    Create a prompt formatted for Gemma 3 12B-IT model with topic awareness.\n",
    "    \n",
    "    Args:\n",
    "        contexts (list): List of text contexts retrieved based on user query\n",
    "        num_questions (int): Number of questions to generate\n",
    "        user_query (str): The original user query/topic\n",
    "        max_questions (int): Maximum number of questions allowed\n",
    "    \n",
    "    Returns:\n",
    "        str: Formatted prompt string for Gemma 3 model\n",
    "    \"\"\"\n",
    "    \n",
    "    num_questions = min(num_questions, max_questions)\n",
    "    \n",
    "    # Build topic context section if query provided\n",
    "    topic_context = \"\"\n",
    "    if user_query:\n",
    "        topic_context = f\"\"\"\n",
    "TOPIC FOCUS: {user_query}\n",
    "The following contexts were retrieved based on this topic. Generate questions that:\n",
    "- Relate to the main topic: \"{user_query}\"\n",
    "- Explore different aspects of this topic found in the contexts\n",
    "- Connect the topic to broader concepts when relevant\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    prompt = \"\"\"<start_of_turn>user\n",
    "You are a question generation expert. Generate exactly {num_questions} diverse questions based on the provided text contexts.\n",
    "{topic_context}\n",
    "IMPORTANT REQUIREMENTS:\n",
    "1. Output MUST be valid JSON format\n",
    "2. Generate EXACTLY {num_questions} questions\n",
    "3. Each question must have a complete answer from the contexts\n",
    "4. Vary question types (what, why, how, when, explain, compare)\n",
    "5. Do not generate yes/no questions\n",
    "6. Answers should be 1-3 sentences long\n",
    "7. Questions should explore different aspects of the topic\n",
    "\n",
    "CONTEXTS (Retrieved based on topic: \"{query}\"):\n",
    "{contexts}\n",
    "\n",
    "OUTPUT FORMAT - Return ONLY valid JSON array:\n",
    "[\n",
    "{{\"question\": \"Your question here?\", \"answer\": \"Complete answer from the context\"}},\n",
    "{{\"question\": \"Another question?\", \"answer\": \"Another answer\"}}\n",
    "]\n",
    "\n",
    "Generate the questions now:<end_of_turn>\n",
    "<start_of_turn>model\n",
    "\"\"\".format(\n",
    "        num_questions=num_questions,\n",
    "        topic_context=topic_context,\n",
    "        query=user_query if user_query else \"the provided content\",\n",
    "        contexts=format_contexts(contexts)\n",
    "    )\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "e8ef36ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "out3 = book_prompt(query_context, num_questions=3, user_query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "0a510adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start_of_turn>user\n",
      "You are a question generation expert. Generate exactly 3 diverse questions based on the provided text contexts.\n",
      "\n",
      "TOPIC FOCUS: data preparation and analysis\n",
      "The following contexts were retrieved based on this topic. Generate questions that:\n",
      "- Relate to the main topic: \"data preparation and analysis\"\n",
      "- Explore different aspects of this topic found in the contexts\n",
      "- Connect the topic to broader concepts when relevant\n",
      "\n",
      "\n",
      "IMPORTANT REQUIREMENTS:\n",
      "1. Output MUST be valid JSON format\n",
      "2. Generate EXACTLY 3 questions\n",
      "3. Each question must have a complete answer from the contexts\n",
      "4. Vary question types (what, why, how, when, explain, compare)\n",
      "5. Do not generate yes/no questions\n",
      "6. Answers should be 1-3 sentences long\n",
      "7. Questions should explore different aspects of the topic\n",
      "\n",
      "CONTEXTS (Retrieved based on topic: \"data preparation and analysis\"):\n",
      "Context 1:\n",
      "We’ve previously reviewed three common evaluation protocols:\n",
      "Maintaining a hold-out validation set—The way to go when you have plenty of\n",
      "data\n",
      "Doing K-fold cross-validation—The right choice when you have too few samples\n",
      "for hold-out validation to be reliable\n",
      "Doing iterated K-fold validation—For performing highly accurate model evalua-\n",
      "tion when little data is available\n",
      "Just pick one of these. In most cases, the first will work well enough. 4.5.4\n",
      "Preparing your data\n",
      "Once you know what you’re training on, what you’re optimizing for, and how to evalu-\n",
      "ate your approach, you’re almost ready to begin training models. But first, you should\n",
      "format your data in a way that can be fed into a machine-learning model—here, we’ll\n",
      "assume a deep neural network:\n",
      "As you saw previously, your data should be formatted as tensors. The values taken by these tensors should usually be scaled to small values: for\n",
      "example, in the [-1, 1] range or [0, 1] range. Licensed to   <null>\n",
      "\n",
      "113\n",
      "The universal workflow of machine learning\n",
      "If different features take values in different ranges (heterogeneous data), then\n",
      "the data should be normalized. You may want to do some feature engineering, especially for small-data problems.\n",
      "\n",
      "Context 2:\n",
      "Validation score: \n",
      "average of the \n",
      "validation scores \n",
      "of the k folds\n",
      "Trains the final \n",
      "model on all non-\n",
      "test data available\n",
      "Licensed to   <null>\n",
      "\n",
      "101\n",
      "Data preprocessing, feature engineering, and feature learning\n",
      "4.3\n",
      "Data preprocessing, feature engineering, \n",
      "and feature learning\n",
      "In addition to model evaluation, an important question we must tackle before we dive\n",
      "deeper into model development is the following: how do you prepare the input data\n",
      "and targets before feeding them into a neural network? Many data-preprocessing and\n",
      "feature-engineering techniques are domain specific (for example, specific to text data\n",
      "or image data); we’ll cover those in the following chapters as we encounter them in\n",
      "practical examples. For now, we’ll review the basics that are common to all data\n",
      "domains. 4.3.1\n",
      "Data preprocessing for neural networks\n",
      "Data preprocessing aims at making the raw data at hand more amenable to neural\n",
      "networks. This includes vectorization, normalization, handling missing values, and\n",
      "feature extraction. VECTORIZATION\n",
      "All inputs and targets in a neural network must be tensors of floating-point data (or, in\n",
      "specific cases, tensors of integers). Whatever data you need to process—sound,\n",
      "images, text—you must first turn into tensors, a step called data vectorization.\n",
      "\n",
      "Context 3:\n",
      "The data you’ll manipulate will almost always fall into one of the fol-\n",
      "lowing categories:\n",
      "Vector data—2D tensors of shape (samples, features)\n",
      "Timeseries data or sequence data—3D tensors of shape (samples, timesteps,\n",
      "features)\n",
      "Images—4D tensors of shape (samples, height, width, channels) or (samples,\n",
      "channels, height, width)\n",
      "Video—5D tensors of shape (samples, frames, height, width, channels) or\n",
      "(samples, frames, channels, height, width)\n",
      "2.2.9\n",
      "Vector data\n",
      "This is the most common case. In such a dataset, each single data point can be encoded\n",
      "as a vector, and thus a batch of data will be encoded as a 2D tensor (that is, an array of\n",
      "vectors), where the first axis is the samples axis and the second axis is the features axis. Let’s take a look at two examples:\n",
      "An actuarial dataset of people, where we consider each person’s age, ZIP code,\n",
      "and income. Each person can be characterized as a vector of 3 values, and thus\n",
      "an entire dataset of 100,000 people can be stored in a 2D tensor of shape\n",
      "(100000, 3).\n",
      "\n",
      "Context 4:\n",
      "Licensed to   <null>\n",
      "\n",
      "323\n",
      "Key concepts in review\n",
      "Mapping vector data to vector data\n",
      "– Predictive healthcare—Mapping patient medical records to predictions of\n",
      "patient outcomes\n",
      "– Behavioral targeting—Mapping a set of website attributes with data on how\n",
      "long a user will spend on the website\n",
      "– Product quality control—Mapping a set of attributes relative to an instance of a\n",
      "manufactured product with the probability that the product will fail by next\n",
      "year\n",
      "Mapping image data to vector data\n",
      "– Doctor assistant—Mapping slides of medical images with a prediction about\n",
      "the presence of a tumor\n",
      "– Self-driving vehicle—Mapping car dash-cam video frames to steering wheel\n",
      "angle commands\n",
      "– Board game AI—Mapping Go and chess boards to the next player move\n",
      "– Diet helper—Mapping pictures of a dish to its calorie count\n",
      "– Age prediction—Mapping selfies to the age of the person\n",
      "Mapping timeseries data to vector data\n",
      "– Weather prediction—Mapping timeseries of weather data in a grid of locations\n",
      "of weather data the following week at a specific location\n",
      "– Brain-computer interfaces—Mapping timeseries of magnetoencephalogram\n",
      "(MEG) data to computer commands\n",
      "– Behavioral targeting—Mapping timeseries of user interactions on a website to\n",
      "the probability that a user will buy something\n",
      "Mapping text to text\n",
      "– Smart reply—Mapping emails to possible one-line replies\n",
      "– Answering questions—Mapping general-knowledge questions to answers\n",
      "– Summarization—Mapping a long article to a short summary of the article\n",
      "Mapping images to text\n",
      "– Captioning—Mapping images to short captions describing the contents of\n",
      "the images\n",
      "Mapping text to images\n",
      "– Conditioned image generation—Mapping a short text description to images\n",
      "matching the description\n",
      "– Logo generation/selection—Mapping the name and description of a company\n",
      "to the company’s logo\n",
      "Mapping images to images\n",
      "– Super-resolution—Mapping downsized images to higher-resolution versions of\n",
      "the same images\n",
      "– Visual depth sensing—Mapping images of indoor environments to maps of\n",
      "depth predictions\n",
      "Licensed to   <null>\n",
      "\n",
      "324\n",
      "CHAPTER 9\n",
      "Conclusions\n",
      "Mapping images and text to text\n",
      "– Visual QA—Mapping images and natural-language questions about the con-\n",
      "tents of images to natural-language answers\n",
      "Mapping video and text to text\n",
      "– Video QA—Mapping short videos and natural-language questions about the\n",
      "contents of videos to natural-language answers\n",
      "Almost anything is possible—but not quite anything.\n",
      "\n",
      "Context 5:\n",
      "Could a computer surprise us? Rather than programmers crafting data-processing\n",
      "rules by hand, could a computer automatically learn these rules by looking at data? This question opens the door to a new programming paradigm. In classical pro-\n",
      "gramming, the paradigm of symbolic AI, humans input rules (a program) and data to\n",
      "be processed according to these rules, and out come answers (see figure 1.2). With\n",
      "machine learning, humans input data as well as the answers expected from the data,\n",
      "and out come the rules. These rules can then be applied to new data to produce orig-\n",
      "inal answers. A machine-learning system is trained rather than explicitly programmed. It’s presented\n",
      "with many examples relevant to a task, and it finds statistical structure in these exam-\n",
      "ples that eventually allows the system to come up with rules for automating the task. For instance, if you wished to automate the task of tagging your vacation pictures, you\n",
      "could present a machine-learning system with many examples of pictures already\n",
      "tagged by humans, and the system would learn statistical rules for associating specific\n",
      "pictures to specific tags. 1 A. M. Turing, “Computing Machinery and Intelligence,” Mind 59, no. 236 (1950): 433-460.\n",
      "\n",
      "Context 6:\n",
      "This is easy: the\n",
      "data is already numerical, so you don’t need to do any vectorization. But each\n",
      "timeseries in the data is on a different scale (for example, temperature is typi-\n",
      "cally between -20 and +30, but atmospheric pressure, measured in mbar, is\n",
      "around 1,000). You’ll normalize each timeseries independently so that they all\n",
      "take small values on a similar scale. Write a Python generator that takes the current array of float data and yields\n",
      "batches of data from the recent past, along with a target temperature in the\n",
      "future. Because the samples in the dataset are highly redundant (sample N and\n",
      "sample N + 1 will have most of their timesteps in common), it would be wasteful\n",
      "to explicitly allocate every sample. Instead, you’ll generate the samples on the\n",
      "fly using the original data. You’ll preprocess the data by subtracting the mean of each timeseries and dividing by\n",
      "the standard deviation. You’re going to use the first 200,000 timesteps as training data,\n",
      "so compute the mean and standard deviation only on this fraction of the data. mean = float_data[:200000].mean(axis=0)\n",
      "float_data -= mean\n",
      "std = float_data[:200000].std(axis=0)\n",
      "float_data /= std\n",
      "Listing 6.33 shows the data generator you’ll use.\n",
      "\n",
      "OUTPUT FORMAT - Return ONLY valid JSON array:\n",
      "[\n",
      "{\"question\": \"Your question here?\", \"answer\": \"Complete answer from the context\"},\n",
      "{\"question\": \"Another question?\", \"answer\": \"Another answer\"}\n",
      "]\n",
      "\n",
      "Generate the questions now:<end_of_turn>\n",
      "<start_of_turn>model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(out3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15860d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
